---
layout: default
nav_active: index
title: CORAL Project
description: CORAL Project.
lang: de
page_name: index
---

<main class="uk-section uk-section-default" uk-height-viewport="expand: true">
  <div class="uk-container">
    <div class="uk-container uk-margin-small">
      <h1 class="uk-margin-remove-top">
        Fundierte Sprachmodelle auf proprietären Daten
      </h1>
      <div>
        <ul class="uk-list">
          <li>
            <span data-uk-icon="chevron-down"></span
            ><a class="uk-margin-small-right" href="#goals">Projektziele</a>
          </li>
          <li>
            <span data-uk-icon="chevron-down"></span
            ><a class="uk-margin-small-right" href="#events">Events</a>
          </li>
          <li>
            <span data-uk-icon="chevron-down"></span
            ><a class="uk-margin-small-right" href="#publications"
              >Publikationen</a
            >
          </li>
          <li>
            <span data-uk-icon="chevron-down"></span
            ><a class="uk-margin-small-right" href="#data"
              >Daten</a
            >
          </li>
          <li>
            <span data-uk-icon="chevron-down"></span
            ><a class="uk-margin-small-right" href="#awards"
              >Awards</a
            >
          </li>
          <li>
            <span data-uk-icon="chevron-down"></span
            ><a class="uk-margin-small-right" href="#partners">Partner</a>
          </li>
        </ul>
      </div>
    </div>

    <div class="uk-container uk-margin-medium">
      <h2 id="goals">Projektziele</h2>

      <p>
        Die Nutzung von Sprachmodellen unterliegt häufig einschränkenden
        Anforderungen, sogenannten Constraints. Wenn zum Beispiel
        lizenzrechtlich beschränkte Daten für das Training verwendet werden,
        sollen diese regelmäßig nicht in künstlich generierten Texten
        reproduziert werden. Aussagen in generierten Texten sollen darüber
        hinaus anhand von Quellen transparent nachvollziehbar sein. Solche und
        ähnliche Anforderungen sind für viele Institutionen und Unternehmen
        unverzichtbar für den produktiven und sicheren Einsatz von
        Sprachmodellen. Die Frage ist also, ob und wie Constraints bei der
        Konstruktion von Sprachmodellen berücksichtigt werden können. Genau hier
        setzt das Forschungsvorhaben „CORAL“ an und will Künstliche Intelligenz
        flexibler, resilienter und effizienter gestalten.
      </p>

      <div
        class="uk-grid-small uk-child-width-1-2@m uk-child-width-1-1@s goals-image"
        uk-grid
      >
        <img
          class="uk-preserve-width"
          src="{{ '/img/coral-illustration-small.png' | relative_url }}"
          alt="Coral Illustration"
        />
        <div>
          <h3>Daten</h3>
          <p>
            CORAL nutzt Daten der beteiligten Partner. Dazu gehören die digitalen Bestände der Deutschen Nationalbibliothek (DNB) sowie Web-Crawls aus dem Internet Archive und dem Common Crawl im Umfang von mehreren Petabyte, langjährige Crawls europäischer Nachrichten aus dem Wortschatz Leipzig und proprietäre Daten aus dem Finanzsektor. Mit Ausnahme des Common Crawls waren diese Daten bisher nicht für das Training von LLMs nutzbar, da sie aus rechtlichen Gründen nicht in ihrer ursprünglichen Form öffentlich zugänglich sind. Wir untersuchen daher, inwieweit diese Daten in obfuskierter Form rechtskonform für das Training von LLMs verwendet werden können und wie weit die Obfuskierung der Daten gehen darf, um nützliche große Sprachmodelle zu erstellen.
          </p>


          <h3 class="uk-margin-small">Vorgehen</h3>
          <p>
            Das Projekt untersucht, ob praktisch nutzbare Sprachmodelle auf
            Basis von Texten trainiert werden können, die nur in verschiedenen
            eingeschränkten Formen zur Verfügung gestellt werden dürfen.
            Außerdem werden Methoden entwickelt, um Texte unter Berücksichtigung
            von Fachwissen mit Quellenangaben zu generieren. Insbesondere soll
            die Textreproduktion aus den Trainingsdaten vermieden, jedoch
            vorgegebene Quellen akkurat wiedergeben, werden. Diese Verfahren
            werden in aufwendigen Experimenten evaluiert und mit Partnern aus
            dem Finanzwesen, GLAM-Institutionen (Kultur- und
            Gedächtnisinstitutionen) und der Privatwirtschaft getestet.
          </p>
        </div>
      </div>

      <h3 class="uk-margin-small">Innovationen und Perspektiven</h3>
      <p>
      Erwartet werden innovative Ergebnisse und Erkenntnisse in drei
      Kernabschnitten bei der Entwicklung und Nutzung von Sprachmodellen,
      sowohl in der Gesellschaft, Wissenschaft als auch Industrie: (1)&nbsp;Berücksichtigung bisher eingeschränkter Trainingsdaten; (2)&nbsp;Modellarchitekturen unter Berücksichtigung von Constraints, die u.a.
      die Reproduktion von Trainingsdaten vermeiden und (3)&nbsp;Verweis auf
      relevante und verlässliche Quellen, auf die der generierte Text
      basiert. Durch den exemplarischen Transfer dieser Ansätze werden
      Flexibilität als auch Effektivität sicher demonstriert.
      </p>

      <h3 class="uk-margin-small">Research Questions</h3>
      <p>
        Zentrale Forschungsfragen sind: Welche Trainingsmethoden und Modellarchitekturen sind robust gegenüber Datenbeschränkungen? Wie ressourceneffizient lassen sich nützliche große Sprachmodelle trainieren? Welche Methoden der Verschleierung, des Verlernens und der negierten Augmentierung verhindern wirksam die Offenlegung geschützter Daten? Wie können die Transparenz und Solidität, Originalität und Referenzierbarkeit der generierten Texte sichergestellt werden? Wie anfällig sind die Methoden zur Sicherung der Trainingsdaten von LLMs?
      </p>
      <p>
          CORAL leistet damit einen wichtigen Beitrag zur Etablierung eines deutschen Marktes für große Sprachmodelle.
      </p>
    </div>
      
    <div class="uk-container uk-margin-medium">
      <h2 id="events">Events</h2>
      {% include events.html %}

      <h2 id="publications">Publikationen</h2>
      <div>
        {% include publications.html %}
      </div>

      <h2 id="data">Daten</h2>
      <div>
        {% include data.html %}
      </div>

      <h2 id="awards">Awards</h2>
      <div>
        {% include awards.html %}
      </div>

      <h2 id="partners">Partner</h2>

      <h3>Institute für Angewandte Informatik e.V.</h3>
      <div
        data-uk-grid
        class="uk-grid uk-grid-match uk-grid-small thumbnail-card-grid"
      >
        {% include people-cards/heyer.html %} {% include
        people-cards/schroeder.html %} {% include
        people-cards/gallagher.html %} {% include people-cards/stadler.html %}
        {% include people-cards/binder.html %}
      </div>

      <h3>University of Kassel</h3>
      <div
        data-uk-grid
        class="uk-grid uk-grid-match uk-grid-small thumbnail-card-grid"
      >
        {% include people-cards/potthast.html %} {% include
        people-cards/gienapp.html %} {% include people-cards/wiegmann.html %} {%
        include people-cards/ruth.html %}
      </div>

      <h3>Hochschule Anhalt</h3>
      <div
        data-uk-grid
        class="uk-grid uk-grid-match uk-grid-small thumbnail-card-grid"
      >
        {% include people-cards/haenig.html %} {% include
        people-cards/hamotskyi.html %} {% include people-cards/gautam.html %}
      </div>

      <h3>Deutsche Nationalbibliothek</h3>
      <div
        data-uk-grid
        class="uk-grid uk-grid-match uk-grid-small thumbnail-card-grid"
      >
        {% include people-cards/leinen.html %} {% include
        people-cards/genet.html %} {% include people-cards/zimmermann.html %}
      </div>
    </div>
  </div>
</main>
